{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f0f568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Suzehva/time_in_language_models_current/blob/main/ii_accuracy/ii_accuracy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9aa346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae920eb",
   "metadata": {},
   "source": [
    "## Create all prompts where interchanging should cause the model to switch tenses (past/present/future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "701f1b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = \"EleutherAI/pythia-1.4b-deduped-v0\"\n",
    "revision = None\n",
    "\n",
    "USER = 'aditijb'\n",
    "\n",
    "DATA_DIR = f'/nlp/scr/{USER}/data'\n",
    "MODEL_DIR = f'/nlp/scr/{USER}/models'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e471d3d1",
   "metadata": {},
   "source": [
    "## Heatmap with one prompt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39ef940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pyvene' has no attribute 'create_pythia'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m      7\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInlineBackend.figure_formats = [\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotnine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     ggplot,\n\u001b[1;32m     10\u001b[0m     geom_tile,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     scale_y_log10,\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 20\u001b[0m config, tokenizer, pythia \u001b[38;5;241m=\u001b[39m \u001b[43mpyvene\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_pythia\u001b[49m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEleutherAI/pythia-1.4b-deduped-v0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pyvene' has no attribute 'create_pythia'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyvene\n",
    "from pyvene import embed_to_distrib, top_vals, format_token\n",
    "from pyvene import RepresentationConfig, IntervenableConfig, IntervenableModel\n",
    "from pyvene import VanillaIntervention\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "from plotnine import (\n",
    "    ggplot,\n",
    "    geom_tile,\n",
    "    aes,\n",
    "    facet_wrap,\n",
    "    theme,\n",
    "    element_text,\n",
    "    geom_bar,\n",
    "    geom_hline,\n",
    "    scale_y_log10,\n",
    ")\n",
    "\n",
    "config, tokenizer, pythia = pyvene.create_pythia(name=\"EleutherAI/pythia-1.4b-deduped-v0\")\n",
    " # TODO FIGURE THIS OUT!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98155d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simple_position_config(model_type, component, layer):\n",
    "    config = IntervenableConfig(\n",
    "        model_type=model_type,\n",
    "        representations=[\n",
    "            RepresentationConfig(\n",
    "                layer,              # layer\n",
    "                component,          # component\n",
    "                \"pos\",              # intervention unit\n",
    "                1,                  # max number of unit\n",
    "            ),\n",
    "        ],\n",
    "        intervention_types=VanillaIntervention,\n",
    "    )\n",
    "    return config\n",
    "\n",
    "\n",
    "base = tokenizer(\"In 1981 there\", return_tensors=\"pt\")\n",
    "sources = [tokenizer(\"In 2023 there\", return_tensors=\"pt\")]\n",
    "tokens = tokenizer.encode(\" was will\")\n",
    "data = []\n",
    "\n",
    "for layer_i in range(pythia.config.num_hidden_layers):\n",
    "    config = simple_position_config(type(pythia), \"block_output\", layer_i) # TODO don't use MLP\n",
    "    intervenable = IntervenableModel(config, pythia)\n",
    "    for pos_i in range(len(base.input_ids[0])):\n",
    "        \n",
    "        _, counterfactual_outputs = intervenable(\n",
    "            base, sources, {\"sources->base\": pos_i}\n",
    "        )\n",
    "        logits = counterfactual_outputs.logits\n",
    "        distrib = torch.softmax(logits, dim=-1)\n",
    "        # distrib = embed_to_distrib(\n",
    "        #     pythia, counterfactual_outputs.hidden_states[-1], logits=False\n",
    "        # )\n",
    "        # Get the token at the intervention position\n",
    "        intervention_token_id = base.input_ids[0][pos_i].item()\n",
    "        intervention_token = format_token(tokenizer, intervention_token_id)\n",
    "        \n",
    "\n",
    "        for token in tokens:\n",
    "            data.append(\n",
    "                {\n",
    "                    \"token\": format_token(tokenizer, token),\n",
    "                    \"prob\": float(distrib[0][-1][token]),\n",
    "                    \"layer\": f\"f{layer_i}\",\n",
    "                    \"pos\": pos_i,\n",
    "                    \"intervention_token\": intervention_token,  # Added this line\n",
    "                    \"type\": \"block_output\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff165a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from plotnine import options\n",
    "\n",
    "df[\"layer\"] = df[\"layer\"].astype(\"category\")\n",
    "df[\"token\"] = df[\"token\"].astype(\"category\")\n",
    "\n",
    "# layers with 0 at bottom, 15 at top\n",
    "layer_nodes = [f\"f{l}\" for l in range(pythia.config.num_hidden_layers)]\n",
    "df[\"layer\"] = pd.Categorical(df[\"layer\"], categories=layer_nodes, ordered=True)\n",
    "\n",
    "# Order intervention tokens by their position in the sentence\n",
    "intervention_token_order = []\n",
    "for pos_i in range(len(base.input_ids[0])):\n",
    "    intervention_token_id = base.input_ids[0][pos_i].item()\n",
    "    intervention_token = format_token(tokenizer, intervention_token_id)\n",
    "    intervention_token_order.append(intervention_token)\n",
    "\n",
    "df[\"intervention_token\"] = pd.Categorical(\n",
    "    df[\"intervention_token\"],\n",
    "    categories=intervention_token_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "g = (\n",
    "    ggplot(df)\n",
    "    + geom_tile(aes(x=\"intervention_token\", y=\"layer\", fill=\"prob\"), raster=False)\n",
    "    + facet_wrap(\"~token\")\n",
    "    + theme(axis_text_x=element_text(rotation=90))\n",
    ")\n",
    "\n",
    "options.figure_size = (8, 6)  # optional\n",
    "g\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
