{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f0f568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Suzehva/time_in_language_models_current/blob/main/ii_accuracy/ii_accuracy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9aa346e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/user/23806/ipykernel_208340/2376787482.py\", line 11, in <module>\n",
      "    set_seed(0)\n",
      "  File \"/tmp/user/23806/ipykernel_208340/2376787482.py\", line 8, in set_seed\n",
      "    torch.manual_seed(seed)\n",
      "  File \"/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/site-packages/torch/random.py\", line 46, in manual_seed\n",
      "    return default_generator.manual_seed(seed)\n",
      "/nlp/scr/aditijb/miniconda3/envs/time-env/lib/python3.10/site-packages/torch/random.py:46: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  return default_generator.manual_seed(seed)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae920eb",
   "metadata": {},
   "source": [
    "## Create all prompts where interchanging should cause the model to switch tenses (past/present/future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "701f1b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = \"allenai/OLMo-2-0425-1B\"\n",
    "revision = None\n",
    "\n",
    "USER = 'aditijb'\n",
    "\n",
    "DATA_DIR = f'/nlp/scr/{USER}/data'\n",
    "MODEL_DIR = f'/nlp/scr/{USER}/models'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e471d3d1",
   "metadata": {},
   "source": [
    "## Heatmap with one prompt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e39ef940",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'transformers.models' has no attribute 'llava'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyvene\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyvene\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m embed_to_distrib, top_vals, format_token\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyvene\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RepresentationConfig, IntervenableConfig, IntervenableModel\n",
      "File \u001b[0;32m/juice2/scr2/aditijb/pyvene/pyvene/__init__.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Generic APIs\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_generators\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcausal_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CausalModel\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintervenable_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     IntervenableModel,\n\u001b[1;32m      7\u001b[0m     IntervenableNdifModel,\n\u001b[1;32m      8\u001b[0m     build_intervenable_model,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_intervenable_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntervenableConfig\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_intervenable_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RepresentationConfig\n",
      "File \u001b[0;32m/juice2/scr2/aditijb/pyvene/pyvene/models/intervenable_base.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintervention_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterventions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/juice2/scr2/aditijb/pyvene/pyvene/models/modeling_utils.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintervenable_modelcard\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterventions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/juice2/scr2/aditijb/pyvene/pyvene/models/intervenable_modelcard.py:58\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m output_to_subcomponent_fn_mapping\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m scatter_intervention_output_fn_mapping\n\u001b[1;32m     51\u001b[0m type_to_module_mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     52\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mgpt2\u001b[38;5;241m.\u001b[39mmodeling_gpt2\u001b[38;5;241m.\u001b[39mGPT2Model: gpt2_type_to_module_mapping,\n\u001b[1;32m     53\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mgpt2\u001b[38;5;241m.\u001b[39mmodeling_gpt2\u001b[38;5;241m.\u001b[39mGPT2LMHeadModel: gpt2_lm_type_to_module_mapping,\n\u001b[1;32m     54\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mgpt2\u001b[38;5;241m.\u001b[39mmodeling_gpt2\u001b[38;5;241m.\u001b[39mGPT2ForSequenceClassification: gpt2_classifier_type_to_module_mapping,\n\u001b[1;32m     55\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mllama\u001b[38;5;241m.\u001b[39mmodeling_llama\u001b[38;5;241m.\u001b[39mLlamaModel: llama_type_to_module_mapping,\n\u001b[1;32m     56\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mllama\u001b[38;5;241m.\u001b[39mmodeling_llama\u001b[38;5;241m.\u001b[39mLlamaForCausalLM: llama_lm_type_to_module_mapping,\n\u001b[1;32m     57\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mllama\u001b[38;5;241m.\u001b[39mmodeling_llama\u001b[38;5;241m.\u001b[39mLlamaForSequenceClassification: llama_classifier_type_to_module_mapping,\n\u001b[0;32m---> 58\u001b[0m     \u001b[43mhf_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllava\u001b[49m\u001b[38;5;241m.\u001b[39mmodeling_llava\u001b[38;5;241m.\u001b[39mLlavaForConditionalGeneration: llava_type_to_module_mapping,\n\u001b[1;32m     59\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mgpt_neo\u001b[38;5;241m.\u001b[39mmodeling_gpt_neo\u001b[38;5;241m.\u001b[39mGPTNeoModel: gpt_neo_type_to_module_mapping,\n\u001b[1;32m     60\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mgpt_neo\u001b[38;5;241m.\u001b[39mmodeling_gpt_neo\u001b[38;5;241m.\u001b[39mGPTNeoForCausalLM: gpt_neo_lm_type_to_module_mapping,\n\u001b[1;32m     61\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mgpt_neox\u001b[38;5;241m.\u001b[39mmodeling_gpt_neox\u001b[38;5;241m.\u001b[39mGPTNeoXModel: gpt_neox_type_to_module_mapping,\n\u001b[1;32m     62\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mgpt_neox\u001b[38;5;241m.\u001b[39mmodeling_gpt_neox\u001b[38;5;241m.\u001b[39mGPTNeoXForCausalLM: gpt_neox_lm_type_to_module_mapping,\n\u001b[1;32m     63\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mmistral\u001b[38;5;241m.\u001b[39mmodeling_mistral\u001b[38;5;241m.\u001b[39mMistralModel: mistral_type_to_module_mapping,\n\u001b[1;32m     64\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mmistral\u001b[38;5;241m.\u001b[39mmodeling_mistral\u001b[38;5;241m.\u001b[39mMistralForCausalLM: mistral_lm_type_to_module_mapping,\n\u001b[1;32m     65\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mgemma\u001b[38;5;241m.\u001b[39mmodeling_gemma\u001b[38;5;241m.\u001b[39mGemmaModel: gemma_type_to_module_mapping,\n\u001b[1;32m     66\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mgemma\u001b[38;5;241m.\u001b[39mmodeling_gemma\u001b[38;5;241m.\u001b[39mGemmaForCausalLM: gemma_lm_type_to_module_mapping,\n\u001b[1;32m     67\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mgemma\u001b[38;5;241m.\u001b[39mmodeling_gemma\u001b[38;5;241m.\u001b[39mGemmaForSequenceClassification: gemma_classifier_type_to_module_mapping,\n\u001b[1;32m     68\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mgemma2\u001b[38;5;241m.\u001b[39mmodeling_gemma2\u001b[38;5;241m.\u001b[39mGemma2Model: gemma2_type_to_module_mapping,\n\u001b[1;32m     69\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mgemma2\u001b[38;5;241m.\u001b[39mmodeling_gemma2\u001b[38;5;241m.\u001b[39mGemma2ForCausalLM: gemma2_lm_type_to_module_mapping,\n\u001b[1;32m     70\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39molmo\u001b[38;5;241m.\u001b[39mmodeling_olmo\u001b[38;5;241m.\u001b[39mOlmoModel: olmo_type_to_module_mapping,\n\u001b[1;32m     71\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39molmo\u001b[38;5;241m.\u001b[39mmodeling_olmo\u001b[38;5;241m.\u001b[39mOlmoForCausalLM: olmo_lm_type_to_module_mapping,\n\u001b[1;32m     72\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39molmo2\u001b[38;5;241m.\u001b[39mmodeling_olmo2\u001b[38;5;241m.\u001b[39mOlmo2Model: olmo2_type_to_module_mapping,\n\u001b[1;32m     73\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39molmo2\u001b[38;5;241m.\u001b[39mmodeling_olmo2\u001b[38;5;241m.\u001b[39mOlmo2ForCausalLM: olmo2_lm_type_to_module_mapping,\n\u001b[1;32m     74\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mqwen3\u001b[38;5;241m.\u001b[39mmodeling_qwen3\u001b[38;5;241m.\u001b[39mQwen3Model: qwen3_type_to_module_mapping,\n\u001b[1;32m     75\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mqwen3\u001b[38;5;241m.\u001b[39mmodeling_qwen3\u001b[38;5;241m.\u001b[39mQwen3ForCausalLM: qwen3_lm_type_to_module_mapping,\n\u001b[1;32m     76\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mesm\u001b[38;5;241m.\u001b[39mmodeling_esm\u001b[38;5;241m.\u001b[39mEsmModel: esm_type_to_module_mapping,\n\u001b[1;32m     77\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mesm\u001b[38;5;241m.\u001b[39mmodeling_esm\u001b[38;5;241m.\u001b[39mEsmForMaskedLM: esm_mlm_type_to_module_mapping,\n\u001b[1;32m     78\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mblip\u001b[38;5;241m.\u001b[39mmodeling_blip\u001b[38;5;241m.\u001b[39mBlipForQuestionAnswering: blip_type_to_module_mapping,\n\u001b[1;32m     79\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mblip\u001b[38;5;241m.\u001b[39mmodeling_blip\u001b[38;5;241m.\u001b[39mBlipForImageTextRetrieval: blip_itm_type_to_module_mapping,\n\u001b[1;32m     80\u001b[0m     MLPModel: mlp_type_to_module_mapping,\n\u001b[1;32m     81\u001b[0m     MLPForClassification: mlp_classifier_type_to_module_mapping,\n\u001b[1;32m     82\u001b[0m     GRUModel: gru_type_to_module_mapping,\n\u001b[1;32m     83\u001b[0m     GRULMHeadModel: gru_lm_type_to_module_mapping,\n\u001b[1;32m     84\u001b[0m     GRUForClassification: gru_classifier_type_to_module_mapping,\n\u001b[1;32m     85\u001b[0m     BackpackGPT2LMHeadModel: backpack_gpt2_lm_type_to_module_mapping,\n\u001b[1;32m     86\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mqwen2\u001b[38;5;241m.\u001b[39mmodeling_qwen2\u001b[38;5;241m.\u001b[39mQwen2Model: qwen2_type_to_module_mapping,\n\u001b[1;32m     87\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mqwen2\u001b[38;5;241m.\u001b[39mmodeling_qwen2\u001b[38;5;241m.\u001b[39mQwen2ForCausalLM: qwen2_lm_type_to_module_mapping,\n\u001b[1;32m     88\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mqwen2\u001b[38;5;241m.\u001b[39mmodeling_qwen2\u001b[38;5;241m.\u001b[39mQwen2ForSequenceClassification: qwen2_classifier_type_to_module_mapping,\n\u001b[1;32m     89\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mmllama\u001b[38;5;241m.\u001b[39mmodeling_mllama\u001b[38;5;241m.\u001b[39mMllamaForConditionalGeneration: mllama_type_to_module_mapping,\n\u001b[1;32m     90\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mgpt_oss\u001b[38;5;241m.\u001b[39mmodeling_gpt_oss\u001b[38;5;241m.\u001b[39mGptOssModel: gpt_oss_type_to_module_mapping,\n\u001b[1;32m     91\u001b[0m     hf_models\u001b[38;5;241m.\u001b[39mgpt_oss\u001b[38;5;241m.\u001b[39mmodeling_gpt_oss\u001b[38;5;241m.\u001b[39mGptOssForCausalLM: gpt_oss_lm_type_to_module_mapping,\n\u001b[1;32m     92\u001b[0m }\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m enable_blip:\n\u001b[1;32m     94\u001b[0m     type_to_module_mapping[BlipWrapper] \u001b[38;5;241m=\u001b[39m blip_wrapper_type_to_module_mapping\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'transformers.models' has no attribute 'llava'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyvene\n",
    "from pyvene import embed_to_distrib, top_vals, format_token\n",
    "from pyvene import RepresentationConfig, IntervenableConfig, IntervenableModel\n",
    "from pyvene import VanillaIntervention\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "from plotnine import (\n",
    "    ggplot,\n",
    "    geom_tile,\n",
    "    aes,\n",
    "    facet_wrap,\n",
    "    theme,\n",
    "    element_text,\n",
    "    geom_bar,\n",
    "    geom_hline,\n",
    "    scale_y_log10,\n",
    ")\n",
    "\n",
    "config, tokenizer, olmo = pyvene.create_olmo2(name=\"allenai/OLMo-2-0425-1B\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98155d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simple_position_config(model_type, component, layer):\n",
    "    config = IntervenableConfig(\n",
    "        model_type=model_type,\n",
    "        representations=[\n",
    "            RepresentationConfig(\n",
    "                layer,              # layer\n",
    "                component,          # component\n",
    "                \"pos\",              # intervention unit\n",
    "                1,                  # max number of unit\n",
    "            ),\n",
    "        ],\n",
    "        intervention_types=VanillaIntervention,\n",
    "    )\n",
    "    return config\n",
    "\n",
    "\n",
    "base = tokenizer(\"In 1981 there\", return_tensors=\"pt\")\n",
    "sources = [tokenizer(\"In 2023 there\", return_tensors=\"pt\")]\n",
    "tokens = tokenizer.encode(\" was will\")\n",
    "data = []\n",
    "\n",
    "for layer_i in range(olmo.config.num_hidden_layers):\n",
    "    config = simple_position_config(type(olmo), \"block_output\", layer_i) # TODO don't use MLP\n",
    "    intervenable = IntervenableModel(config, olmo)\n",
    "    for pos_i in range(len(base.input_ids[0])):\n",
    "        \n",
    "        _, counterfactual_outputs = intervenable(\n",
    "            base, sources, {\"sources->base\": pos_i}\n",
    "        )\n",
    "        logits = counterfactual_outputs.logits\n",
    "        distrib = torch.softmax(logits, dim=-1)\n",
    "        # distrib = embed_to_distrib(\n",
    "        #     olmo, counterfactual_outputs.hidden_states[-1], logits=False\n",
    "        # )\n",
    "        # Get the token at the intervention position\n",
    "        intervention_token_id = base.input_ids[0][pos_i].item()\n",
    "        intervention_token = format_token(tokenizer, intervention_token_id)\n",
    "        \n",
    "\n",
    "        for token in tokens:\n",
    "            data.append(\n",
    "                {\n",
    "                    \"token\": format_token(tokenizer, token),\n",
    "                    \"prob\": float(distrib[0][-1][token]),\n",
    "                    \"layer\": f\"f{layer_i}\",\n",
    "                    \"pos\": pos_i,\n",
    "                    \"intervention_token\": intervention_token,  # Added this line\n",
    "                    \"type\": \"block_output\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff165a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from plotnine import ggplot, aes, geom_tile, facet_wrap, theme, element_text, labs, options\n",
    "\n",
    "# Layers categorical (0 at bottom, max at top)\n",
    "layer_nodes = [f\"f{l}\" for l in range(olmo.config.num_hidden_layers)]\n",
    "df[\"layer\"] = pd.Categorical(df[\"layer\"], categories=layer_nodes, ordered=True)\n",
    "\n",
    "# Tokens categorical\n",
    "df[\"token\"] = df[\"token\"].astype(\"category\")\n",
    "\n",
    "# Build x-axis labels: show swapped tokens when base != source\n",
    "base_ids = base.input_ids[0]\n",
    "source_ids = sources[0].input_ids[0]\n",
    "\n",
    "base_tokens = [format_token(tokenizer, tid.item()) for tid in base_ids]\n",
    "source_tokens = [format_token(tokenizer, tid.item()) for tid in source_ids]\n",
    "\n",
    "x_labels = []\n",
    "for b_tok, s_tok in zip(base_tokens, source_tokens):\n",
    "    if b_tok != s_tok:\n",
    "        x_labels.append(f\"{b_tok} <- {s_tok}\")\n",
    "    else:\n",
    "        x_labels.append(b_tok)\n",
    "\n",
    "# Map df intervention tokens to these labels\n",
    "df[\"intervention_token\"] = pd.Categorical(\n",
    "    [x_labels[pos] for pos in df[\"pos\"]],\n",
    "    categories=x_labels,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Plot\n",
    "g = (\n",
    "    ggplot(df)\n",
    "    + geom_tile(aes(x=\"intervention_token\", y=\"layer\", fill=\"prob\"), raster=False)\n",
    "    + facet_wrap(\"~token\")\n",
    "    + theme(axis_text_x=element_text(rotation=90, ha='right'))\n",
    "    + labs(x=\"Intervention Token (base ← source)\", y=\"Layer\", fill=\"Probability\")\n",
    ")\n",
    "\n",
    "options.figure_size = (12, 6)  # match first plot\n",
    "g\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
